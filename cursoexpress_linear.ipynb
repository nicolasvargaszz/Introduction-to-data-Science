{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBgwDCyJ8zhd"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el conjunto de datos \"Digits\"\n",
        "digits = datasets.load_digits()\n",
        "X, y = digits.data, digits.target\n"
      ],
      "metadata": {
        "id": "xXjUZjpy87mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir el conjunto de datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "azlx89Fu-tYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear y entrenar el modelo SVM\n",
        "model = SVC()\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "IiR2BVlC-vkT",
        "outputId": "f5772077-b350-4441-80e3-591c1096389a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "wQttNhFS-xhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la precisión del modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Precisión del modelo: {accuracy:.2f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYvPG5o4-03L",
        "outputId": "ba0d41b4-f15c-4697-e566-244bec1ee316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ahora usaremos otro modelo completamente aparte para probarlo con imagenes escritas a mano"
      ],
      "metadata": {
        "id": "JuU7NYYP-5jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Redefinir el tamaño de las imágenes a 28x28 píxeles (el formato esperado por el modelo simple)\n",
        "new_size = (28, 28)\n",
        "\n",
        "# Ruta de la imagen de prueba (modifica esta ruta según la ubicación de tu imagen)\n",
        "imagen_prueba = 'num2.jpeg'\n",
        "\n",
        "# Cargar la imagen de prueba y redimensionarla a 28x28 píxeles\n",
        "img = io.imread(imagen_prueba, as_gray=True)\n",
        "img = resize(img, new_size, anti_aliasing=True, mode='reflect')\n",
        "\n",
        "# Mostrar la imagen de prueba (28x28 píxeles)\n",
        "plt.figure(figsize=(4, 4))\n",
        "plt.imshow(img, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "plt.title(\"Imagen de Prueba (28x28 píxeles)\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Aplanar la imagen para que coincida con el formato de entrada del modelo (28x28)\n",
        "img_flatten = img.flatten().reshape(1, 28, 28)\n",
        "\n",
        "# Crear un modelo simple para la clasificación de dígitos\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')  # 10 clases para los dígitos del 0 al 9\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo con el conjunto de datos MNIST\n",
        "mnist = keras.datasets.mnist\n",
        "(digits_train, digits_train_labels), (digits_test, digits_test_labels) = mnist.load_data()\n",
        "digits_train = digits_train / 255.0\n",
        "model.fit(digits_train, digits_train_labels, epochs=5)\n",
        "\n",
        "# Realizar la predicción con el modelo simple\n",
        "predicted_class = model.predict(img_flatten)\n",
        "\n",
        "# Obtener la clase predicha\n",
        "predicted_class = np.argmax(predicted_class)\n",
        "\n",
        "print(f'La imagen se clasifica como el dígito: {predicted_class}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "eE1FAjq0AD16",
        "outputId": "a06a7dfd-3ee8-43b6-e08e-149fe8d1a0d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAFeCAYAAADnm4a1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAizUlEQVR4nO3de3AV9f3/8dfJPSQk4S4ESCFBgQwoA+JwKfgFgXIRkSJop8rFIIjQgqIgVUC0aMcLYAEBqWAtaLnUilKhQqPgBUdBKMqdBNBIIeGqCUkg+fz+cHJ+HJIP7EdZQH0+ZpyRzfvsfs7untfZnLPvfALGGCMAQDlhl3sAAHClIiABwIKABAALAhIALAhIALAgIAHAgoAEAAsCEgAsCEjgZ2rPnj2aPHmydu7cebmHcsUiIC+zG2+8UTfeeOPlHoav3n33XQUCAS1btuySbG/JkiWqWrWqvv3220uyvR8jY4wGDx6sDz/8UI0aNbro6/fzvN62bZsiIiL0+eef+7L+s/kWkAsXLlQgENCnn37q1yZQgUGDBikQCAT/S0hI0LXXXqtnn31WRUVFl3t4vispKdGkSZM0atQoxcfHS5IKCgo0a9Ysde3aVbVr11blypXVokULvfDCCyopKSm3joMHD+qee+5RgwYNFBsbq9TUVN1///06cuSI83gu57bPZ9asWcrKytKiRYsUFvbjuk5q2rSpevbsqYkTJ/q+rQjft4BLLjo6WvPnz5ckHT9+XMuXL9fYsWP1ySef6LXXXrvMo/PXm2++qZ07d+qee+4JLsvKytKoUaPUuXNn3X///UpISNDq1as1YsQIbdiwQS+//HKw9ttvv1WbNm2Un5+vESNGqF69etqyZYtmzpypzMxMbdy40SlQLue2bQ4cOKBHH31UK1asUI0aNX7w+i6H4cOHq0ePHtq7d69SU1P925DxyYIFC4wk88knn/i1iZ+Ejh07mo4dO1609Q0cONDExcWFLCspKTGtWrUykkxOTk6FjystLTUFBQUXbRxny8zMNJLM0qVLfVn/2Xr37m3at28fsiw3N9d8/vnn5WoHDx5sJJndu3cHly1atMhIMm+99VZI7cSJE40ks2nTJqfxXM5tX04X+7w+V3FxsalSpYp59NFHfduGMcZc0mvrQYMGKT4+XgcOHFCvXr0UHx+v5ORkzZo1S5K0detWderUSXFxcUpJSdHixYtDHn/06FGNHTtWzZo1U3x8vBISEtS9e3dt2bKl3Lb279+v3r17Ky4uTjVr1tSYMWO0evVqBQIBvfvuuyG1H3/8sX71q18pMTFRlSpVUseOHfXBBx+E1EyePFmBQEB79uzRoEGDlJSUpMTERA0ePFgFBQWenv+8efOUmpqq2NhYtW7dWuvXr6+wrqioSJMmTVJaWpqio6NVr149PfTQQ9/7V+SwsLDg50H79u2TJP3iF79Qr169tHr1arVq1UqxsbGaO3eu9u3bp0AgoIULF5ZbTyAQ0OTJk0OW5eTkaMiQIapVq5aio6OVnp6ul156qcJxlJSUaMKECbrqqqsUFxen3r1768svvwypWb9+vW677TbVr18/+NzHjBmjU6dOXfB5FhYWatWqVbrppptCllevXl3p6enl6m+99VZJ0vbt24PLTp48KUmqVatWSG3t2rUlSbGxsZKk//znPwoLCyv3a97ixYsVCAT0wgsv+LZtm7LXV1ZWlrp166a4uDjVqVNHU6ZMkTnnj3adfSxPnTqlxo0bq3HjxiH7+ejRo6pdu7batm0b/DigtLRU06dPV3p6umJiYlSrVi0NGzZMx44dO+/YJO/n9TvvvKP27dsrKSlJ8fHxuuaaazRhwoSQmsjISN1444164403LrjdH8Sv5K3oCnLgwIEmJibGNG3a1AwfPtzMmjXLtG3b1kgyCxYsMHXq1DEPPvig+fOf/2zS09NNeHi4ycrKCj7+k08+MampqWb8+PFm7ty5ZsqUKSY5OdkkJiaGXBl9++23pmHDhiY2NtaMHz/eTJ8+3bRu3dpce+21RpLJzMwM1q5du9ZERUWZNm3amGeffdZMmzbNNG/e3ERFRZmPP/44WDdp0iQjybRo0cL07dvXzJ4922RkZBhJ5qGHHrrg/pg/f76RZNq2bWuef/55M3r0aJOUlGQaNmwY8k5bUlJiunbtaipVqmRGjx5t5s6da0aOHGkiIiLMLbfccsHtVHQFaYwxt956q5FkduzYYYwxJiUlxaSlpZkqVaqY8ePHmzlz5pjMzEyTnZ0dPB7nkmQmTZoU/Pf//vc/U7duXVOvXj0zZcoU88ILL5jevXsbSWbatGnBurIryGbNmpnmzZub5557zowfP97ExMSYq6++OuTKddSoUaZHjx5m6tSpZu7cuebuu+824eHhpl+/fhd87u+//76RZFasWHHBWmOMmTdvnpFkPvzww+CyL774woSFhZm2bduajz76yHz55Zdm5cqVpm7duqZPnz4hj7/vvvtMRESE2bhxozHGmK+//tpUrVrV3HTTTaa0tNTXbVek7PXVqFEjc+edd5qZM2eaXr16GUnlrrTOPZYbNmww4eHhZsyYMcFlt99+u4mNjTU7d+4MLsvIyDARERFm6NChZs6cOWbcuHEmLi7OXH/99aa4uDhYd+4VpNfz+vPPPzdRUVGmVatWZsaMGWbOnDlm7NixpkOHDuWe7xNPPGHCwsLMiRMnLrhvvq9LHpCSzNSpU4PLjh07ZmJjY00gEDCvvfZacPmOHTvKHcTCwkJTUlISsp3s7GwTHR1tpkyZElz27LPPGknmn//8Z3DZqVOnTOPGjUMCsrS01DRq1Mh069Yt5IQuKCgwDRo0MF26dAkuKwvIIUOGhGz/1ltvNdWqVTvvviguLjY1a9Y01113nSkqKgouL3uRnH0ivfLKKyYsLMysX78+ZB1z5swxkswHH3xw3m2VBWRubq7Jzc01e/bsMVOnTjWBQMA0b948WJeSkmIkmVWrVoU83iUg7777blO7dm2Tl5cXUnf77bebxMTEYPCVBWRycrI5efJksG7JkiVGkpkxY0ZwWUW/5j/55JMmEAiY/fv3n/e5l70Jbd269bx1xhhTVFRkmjZtaho0aGBOnz5dbj1JSUlGUvC/gQMHlqvLz883aWlpJj093RQWFpqePXuahISEC47zYmy7ImWvr1GjRgWXlZaWmp49e5qoqCiTm5sbXH7usTTGmIcfftiEhYWZdevWmaVLlxpJZvr06cGfr1+/3kgyixYtCnncqlWryi0/NyC9ntfTpk0zkkLGarN48WIjKeRC5mK7LF9fZWRkBP8/KSlJ11xzjeLi4tS/f//g8muuuUZJSUnKysoKLouOjg5+SF1SUqIjR44EL8E3bdoUrFu1apWSk5PVu3fv4LKYmBgNHTo0ZBybN2/W7t279Zvf/EZHjhxRXl6e8vLylJ+fr86dO2vdunUqLS0Neczw4cND/v3LX/5SR44cCf56VJFPP/1Uhw8f1vDhwxUVFRVcPmjQICUmJobULl26VE2aNFHjxo2D48nLy1OnTp0kSZmZmdbtlMnPz1eNGjVUo0YNpaWlacKECWrTpo1ef/31kLoGDRqoW7duF1xfRYwxWr58uW6++WYZY0LG2q1bN504cSLkmEjSXXfdpcqVKwf/3a9fP9WuXVv/+te/gsvO/jUyPz9feXl5atu2rYwx+uyzz847prJveqtUqXLB8Y8cOVLbtm3TzJkzFRER+l1lcnKyWrdurenTp+v111/X/fffr0WLFmn8+PEhdZUqVdLChQu1fft2dejQQStXrtS0adNUv35937d9ofWXCQQCGjlypIqLi7VmzZrzPm7y5MlKT0/XwIEDNWLECHXs2FG/+93vgj9funSpEhMT1aVLl5Dj3bJlS8XHx5/33PR6XiclJUmS3njjjXKvvXOVHee8vLzz1v0Ql/xb7JiYmHLfnCUmJqpu3boKBALllp/92UZpaalmzJih2bNnKzs7O+Q2iWrVqgX/f//+/UpNTS23vrS0tJB/7969W5I0cOBA63hPnDgR8oI79+Qv+9mxY8eUkJBQ4Tr2798vSeXuN4uMjFTDhg3LjWn79u3WbxcPHz5sHWuZmJgYvfnmm5K+e1Np0KCB6tatW66uQYMGF1yXTW5uro4fP6558+Zp3rx5nsZ67vMPBAJKS0sLfi4qffcN68SJE7VixYpyn2udOHHC09jMBf5I/tNPP60XX3xRjz/+uHr06BHysw8++EC9evXShg0b1KpVK0lSnz59lJCQoMcee0xDhgxR06ZNg/Xt2rXTvffeq1mzZqlbt24aMmTIJdt2RcLCwsqdU1dffbUkheznikRFRemll17S9ddfr5iYGC1YsCDkNbR7926dOHFCNWvWrPDx5zs3vZ7XAwYM0Pz585WRkaHx48erc+fO6tu3r/r161fuG/yy43zu6/xiuuQBGR4e7rT87JN96tSpevTRRzVkyBA9/vjjqlq1qsLCwjR69OgLvttUpOwxTz/9tK677roKa8rupXMZ5w9RWlqqZs2a6bnnnqvw5/Xq1bvgOsLDw8t9UVGRij70t51s596zV7bvfvvb31rfYJo3b37BMZy7jS5duujo0aMaN26cGjdurLi4OOXk5GjQoEEXPMZlb5LHjh2r8A1B+u7+3HHjxmn48OF65JFHyv187ty5qlWrVjCgyvTu3VuTJ0/Whx9+GBJSRUVFwS/99u7dq4KCAlWqVOmSbNsPq1evlvTdF167d+8OeRMtLS1VzZo1tWjRogofe75bhrye17GxsVq3bp0yMzO1cuVKrVq1Sn//+9/VqVMn/fvf/w55/ZW9gVavXt3tSTr4Ud0HuWzZMv3f//2f/vKXv4QsP378eMhOSklJ0bZt22SMCXnB79mzJ+RxZfdPJSQkeAqU7yslJUXSd++iZb9SSNLp06eVnZ2ta6+9NmRMW7ZsUefOnX19Z7QpuyI+fvx4yPKyq+AyNWrUUOXKlVVSUuJ535VdsZcxxmjPnj3BIN26dat27dqll19+WXfddVew7p133vG0/saNG0uSsrOz1axZs3I/f+ONN5SRkaG+ffsG75w416FDhyq8gfv06dOSpDNnzoQsnzRpkrZv365nnnlG48aN0/jx4/X8889fkm1XpLS0VFlZWcGrRknatWuXpO/uXDif//73v5oyZYoGDx6szZs3KyMjQ1u3bg1+DJSamqo1a9aoXbt2F/xG/Vwu53VYWJg6d+6szp0767nnntPUqVP1hz/8QZmZmSHnWnZ2tsLCwkKe68X2o7qFPjw8vNyV2tKlS5WTkxOyrFu3bsrJydGKFSuCywoLC/Xiiy+G1LVs2VKpqal65plnKmxLy83NvSjjbtWqlWrUqKE5c+aouLg4uHzhwoXlgqh///7KyckpN1bpu9sx8vPzL8qYbBISElS9enWtW7cuZPns2bND/h0eHq5f//rXWr58eYUtXxXtu7/+9a/65ptvgv9etmyZDh48qO7duwfXKYVejRtjNGPGDE9jb9mypaKioirs3lq3bp1uv/12dejQ4bzdI1dffbUOHTpU7lawV199VZLUokWL4LKPP/5YzzzzjEaPHq0HHnhADz74oGbOnKn33nvP922fz8yZM4P/b4zRzJkzFRkZqc6dO1sfc/r0aQ0aNEh16tTRjBkztHDhQh06dEhjxowJ1vTv318lJSV6/PHHyz3+zJkz5c7ls3k9r48ePVru52W/3Z17O9DGjRuVnp5e7nP8i+lHdQXZq1ev4Dtc27ZttXXrVi1atKjcZy7Dhg3TzJkzdccdd+j3v/+9ateurUWLFikmJkbS//81MiwsTPPnz1f37t2Vnp6uwYMHKzk5WTk5OcrMzFRCQkLws7wfIjIyUk888YSGDRumTp06acCAAcrOztaCBQvKjf3OO+/UkiVLNHz4cGVmZqpdu3YqKSnRjh07tGTJkuB9i37KyMjQU089pYyMDLVq1Urr1q0LXoWc7amnnlJmZqZuuOEGDR06VE2bNtXRo0e1adMmrVmzptzJXrVqVbVv316DBw/WoUOHNH36dKWlpQW/PGvcuLFSU1M1duxY5eTkKCEhQcuXL/d0j5303WevXbt21Zo1azRlypTg8rJ7YgOBgPr166elS5eGPK558+bBq9iRI0dqwYIFuvnmmzVq1CilpKTovffe06uvvqouXbrohhtukPTdG+7AgQPVqFEj/fGPf5QkPfbYY3rzzTc1ePBgbd26VXFxcb5s+0L7YNWqVRo4cKBuuOEGvf3221q5cqUmTJhw3l+Bn3jiCW3evFlr165V5cqV1bx5c02cOFGPPPKI+vXrpx49eqhjx44aNmyYnnzySW3evFldu3ZVZGSkdu/eraVLl2rGjBnq169fhev3el5PmTJF69atU8+ePZWSkqLDhw9r9uzZqlu3rtq3bx9c3+nTp/Xee+9pxIgRF9wnP4hfX4/bbvOp6B69jh07mvT09HLLU1JSTM+ePYP/LiwsNA888ICpXbu2iY2NNe3atTMfffRRhXftZ2VlmZ49e5rY2FhTo0YN88ADD5jly5cbSWbDhg0htZ999pnp27evqVatmomOjjYpKSmmf//+Zu3atcGastt8zr39oOx5ZmdnX3CfzJ492zRo0MBER0ebVq1amXXr1lU49uLiYvOnP/3JpKenm+joaFOlShXTsmVL89hjj13wni/bPj7Xufv2bAUFBebuu+82iYmJpnLlyqZ///7m8OHDFd4acujQIXPfffeZevXqmcjISHPVVVeZzp07m3nz5gVrym7zefXVV83DDz9satasaWJjY03Pnj3L3RKzbds2c9NNN5n4+HhTvXp1M3ToULNlyxbrrUfn+sc//mECgYA5cOBAue3b/jv3Oe3YscP069cv+JxSUlLM2LFjTX5+frBmzJgxJjw8vNwtJp9++qmJiIgw9957r2/btik79nv37g3ec1irVi0zadKkcrfHnb3tjRs3moiIiJDbg4wx5syZM+b66683derUMceOHQsunzdvnmnZsqWJjY01lStXNs2aNTMPPfSQ+frrr4M13/e8Xrt2rbnllltMnTp1TFRUlKlTp4654447zK5du0LW9fbbb5frRPJDwJifz7zY06dP15gxY/TVV18pOTn5cg8HPigpKVHTpk3Vv3//Cn8V/CkbNGiQli1b9rP4K0Z9+vRRIBAod+vaxfaj+gzSxbmtaYWFhZo7d64aNWpEOP6EhYeHa8qUKZo1a9bPIih+jrZv36633nrrkrwB/qg+g3TRt29f1a9fX9ddd51OnDihv/3tb9qxY4f1FgX8dAwYMEADBgy43MOAT5o0aeLpG/2L4ScbkN26ddP8+fO1aNGi4K9dr732Gi8cAJ79rD6DBAAXP9nPIAHghyIgAcCCgAQAC89f0tx5552eV1pRP+nF4DIfR1n/6sWudfn2zOUPaLjUuvxlcZdj4TIGl/3g8jG317/OLimkbfNCXP6ggct6vXb5SFfGcXOpddkPLn834Pv8YRkvXM6z87VFno0rSACwICABwIKABAALAhIALAhIALAgIAHAgoAEAAsCEgAsCEgAsCAgAcDCc6uhSxuPS61L25HLev2aMtWvFjuX9frVyunCpW3OZT+4tJNGRkZ6rnVpm3NpPbXNk14Rl+fm1z5zeW4uryG//mqiy7nu8ty84goSACwISACwICABwIKABAALAhIALAhIALAgIAHAgoAEAAsCEgAsCEgAsPDcaujCr7bEn/IYXFqq/BqvX7PjuXBpb3NpNXTh14yCLi2BfnEZb0SEL/Hg1Pbp0srpx+vi8h8xALhCEZAAYEFAAoAFAQkAFgQkAFgQkABgQUACgAUBCQAWBCQAWBCQAGDhSy+RXy1Vl3uGM0mKjo72XOsy85+LK6GN0mU/uBwLv8br16yGLrUu569LrUs7nl8zYrrMyukXP54bV5AAYEFAAoAFAQkAFgQkAFgQkABgQUACgAUBCQAWBCQAWBCQAGBBQAKAhedWQ5fZ5ly4zLLm0s7k18x0LjPpRUVFea69ElrsXPaZy/ng0nrqcowLCws917rwq5XTr/3r1wyTfp2TLq8hl2PMrIYAcAkRkABgQUACgAUBCQAWBCQAWBCQAGBBQAKABQEJABYEJABYEJAAYOG51dClBexKaAn0qwXMpW3OZQwu+8xlvbGxsZ5rk5KSPNe6tIu57N/c3Fxfav2adc+vGTxduOxfv9ooXWZW9KvWj5lML//RBYArFAEJABYEJABYEJAAYEFAAoAFAQkAFgQkAFgQkABgQUACgAUBCQAWnlsNXdqZ/GofdOEyK1x0dLQv6y0qKvJc67LPXLRr185zbUZGhudal+O2d+9ez7VHjhzxXLtp0ybPtR999JHn2oMHD3qudeFXS6DLOenXbJQus2f61VZbqVIlz7VecQUJABYEJABYEJAAYEFAAoAFAQkAFgQkAFgQkABgQUACgAUBCQAWBCQAWHhuNXThMuOdC5cWJZc2Kb9mS/SLy0yFLvth3759nms3bNjguXbz5s2ea6OiojzXNm3a1HNtmzZtPNdmZmZ6rj127JjnWhcubYkuM/+5tBq68Ov15vLcXM4dr7iCBAALAhIALAhIALAgIAHAgoAEAAsCEgAsCEgAsCAgAcCCgAQACwISACw8txq6zFrm0mro0nbk0s7k18xpfs3C6LLPUlNTPddWr17dc+3ixYs91+7cudNz7cmTJz3XurTCffHFF55r8/PzPdc2adLEl/W6tML51T54+vRpz7Uurwu/ZuWMiPClG9ozriABwIKABAALAhIALAhIALAgIAHAgoAEAAsCEgAsCEgAsCAgAcCCgAQAC899PC6tTy5c2gddaq+E2QddxuDSLubSlujSqrVnzx7PtQUFBZ5rXdrQCgsLfVmvS4udS/tgYmKiL+t1Odddzh2XlmG/2hL9eh27tBd7xRUkAFgQkABgQUACgAUBCQAWBCQAWBCQAGBBQAKABQEJABYEJABYEJAAYOG5D82lPciFS5uUy4yCfs0+6LIfXNozi4qKPNfm5eV5rt2+fbvn2lOnTnmudWnrcmlZczluLrMEJiQkeK51mYUxNjbWc63LueNyLFzOM79mHPWjzU9yayf14zXPFSQAWBCQAGBBQAKABQEJABYEJABYEJAAYEFAAoAFAQkAFgQkAFgQkABg4bnV0KUl8HLPRCb515bo1+yOLi1VBw4c8FyblZXludblWLjsM5dzx6V90OVYuLQaupy/Lm2ULq2GfrUE+jWLqMsxduHyuvBjDFxBAoAFAQkAFgQkAFgQkABgQUACgAUBCQAWBCQAWBCQAGBBQAKABQEJABaeWw0jIjyXOrVfuXBpqXJpUXJpsSssLPRceyW0X7k8N5cWuyth1si4uDjPtTVr1vRcu3//fs+1LuP1a3ZHl5ZLv2YJdFmvS5a4nJMutV5xBQkAFgQkAFgQkABgQUACgAUBCQAWBCQAWBCQAGBBQAKABQEJABYEJABYeO75cWmpcuHSouRXq5ZfLVUuLWAubYl+zTbnsh/8akt0aR9s2LCh59r8/HzPtcnJyZ5rd+7c6bnW5fx1Oc9cjoVf55nLue5yPvi1z7ziChIALAhIALAgIAHAgoAEAAsCEgAsCEgAsCAgAcCCgAQACwISACwISACw8Nxq6NdsaH7N/OdXS5VfXGZ682tWOJdj7LLPqlWr5rm2devWnmurV6/uudalJfDw4cOea7/55hvPtX7MuidJBQUFnmtdXhcu7YMu/MqS4uLi7zOc87r8yQAAVygCEgAsCEgAsCAgAcCCgAQACwISACwISACwICABwIKABAALAhIALDz3rPk1451fLYFXwhhc+DULo8t4XVoY4+PjPde2aNHCl9rPPvvMc+1XX33lufbgwYOea/06z1zW61etX7N9+vUaioyMvOjr5AoSACwISACwICABwIKABAALAhIALAhIALAgIAHAgoAEAAsCEgAsCEgAsPDcW+ZXi5JftS6tT2fOnPFlvS6zwp0+fdpzrV9tn7GxsZ5rW7Zs6bm2d+/enms3bdrkuXbjxo2ea7/88kvPtS6z4/k1U6GLmJgYz7V+tSX6MaOg5NaW6McMqVxBAoAFAQkAFgQkAFgQkABgQUACgAUBCQAWBCQAWBCQAGBBQAKABQEJABaeWw39asdz4dJi51e7mF9tfi7714VL+1VaWprnWpf2wfz8fM+177//vufanJwcz7Uu56RL26fLMXZpPXWpdXluLrUu57oLl3MyOjrac21hYeH3Gc55cQUJABYEJABYEJAAYEFAAoAFAQkAFgQkAFgQkABgQUACgAUBCQAWBCQAWPgyq6ELv9oSXWZD86tVy6VdzIXLelu0aOG5dsiQIZ5rIyMjPdeuXLnSc+3u3bs917q0k7q0t0VFRXmudWkRdRmDS61fM3j61Srr8tr06zXkFVeQAGBBQAKABQEJABYEJABYEJAAYEFAAoAFAQkAFgQkAFgQkABgQUACgIXnVkOXGc5c2qT8mr3NhV8tYC5c9oPL7IMjRozwXFu3bl3Pta+88orn2q1bt3qudZnFrn79+p5rY2JiPNe6tBrGxcX5sl6XmRVdntuBAwc81x46dMhz7b59+zzXnjp1ynNtRITniPIlH7iCBAALAhIALAhIALAgIAHAgoAEAAsCEgAsCEgAsCAgAcCCgAQACwISACw89/G4zETm0pbo12yJfrUEunDZDy7tYn369PFc26RJE8+1e/fu9VybkJDgufa2227zXBsbG+u51qUt0aX28OHDnmu//vprz7UFBQWea/Pz8z3Xujy3WrVqea7Nzc31pdblublwaUv0iitIALAgIAHAgoAEAAsCEgAsCEgAsCAgAcCCgAQACwISACwISACwICABwMKXWQ1dZmRz4TLzX3Fxsedal9nQXPZD5cqVPde2bdvWc23Hjh0917q0ciYlJXmu7dChg+faLVu2eK7NysryXLtz507PtfHx8Z5rXWboy8vL81zrck5GRkZ6rj1z5ozn2qKiIs+1hYWFnmv9em5+tTh73v5FXyMA/EQQkABgQUACgAUBCQAWBCQAWBCQAGBBQAKABQEJABYEJABYEJAAYOG51dClfdCl5cel1mXWMpdZDf2qrVq1qufaTp06ea7dtWuX59qTJ096rs3OzvZc69ISeODAAc+1Lq17LrMEurSTfvPNN55rXVrs/Grzc2kn9asN2OV17NI+6MKPmUy5ggQACwISACwISACwICABwIKABAALAhIALAhIALAgIAHAgoAEAAsCEgAsAsZjn1L37t09r/RKmAHRpbXMpdZlBjmX2dtq167tufbEiROea11a4fyaxc5ln7mcD36147nw69xxGa9LC65Lu6PLeP2qdeGyz06dOuWpjitIALAgIAHAgoAEAAsCEgAsCEgAsCAgAcCCgAQACwISACwISACwICABwMJzj5JfMxW61Lq0Erms16X1yWXmNJdWuD179niudWlv84tLS6DLcbsSnptL657LeeYiPDzcc63LeP06Fi4zFfpVy6yGAHAJEZAAYEFAAoAFAQkAFgQkAFgQkABgQUACgAUBCQAWBCQAWBCQAGDhuUfpSmhR8mtmOpfZB/16bi7tjn7tM5dWLZd95lc7nsux8Ov8dVmvX62yfq3Xr/PsSni9eV7nRV8jAPxEEJAAYEFAAoAFAQkAFgQkAFgQkABgQUACgAUBCQAWBCQAWBCQAGDhudXQpQ3NpdavVjg/ZjiT/BtvdHS051qXdjGX2QddXAmtey6tZS77zK+ZFV1mKnQZQ1FRkedal3PSr/3r1zH2A1eQAGBBQAKABQEJABYEJABYEJAAYEFAAoAFAQkAFgQkAFgQkABgQUACgIXnVkOXlp8roUXJr1Y4v9odXfaZy3hdWg1dZptz4XKM/ZoB0YVfY7gS2l9dnpvLTJsREZ6jxLd8KC4u9lzrFVeQAGBBQAKABQEJABYEJABYEJAAYEFAAoAFAQkAFgQkAFgQkABgQUACgEXAuPQpAcDPCFeQAGBBQAKABQEJABYEJABYEJAAYEFAAoAFAQkAFgQkAFgQkABg8f8AZ69vTkWf8c4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.2562 - accuracy: 0.9267\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1152 - accuracy: 0.9658\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0782 - accuracy: 0.9757\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0579 - accuracy: 0.9825\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0449 - accuracy: 0.9857\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "La imagen se clasifica como el dígito: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG19\n"
      ],
      "metadata": {
        "id": "cpIndzFoahyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Redefinir el tamaño de las imágenes a 64x64 píxeles\n",
        "new_size = (64, 64)\n",
        "\n",
        "# Crear un generador de datos de imágenes\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2  # Añadir un rango de zoom\n",
        ")\n",
        "\n",
        "# Cargar el conjunto de datos CIFAR-10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Redefinir el tamaño de las imágenes en el conjunto de prueba\n",
        "x_test = tf.image.resize(x_test, new_size)\n",
        "\n",
        "# Normalizar las etiquetas\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Redefinir el tamaño de las imágenes en el conjunto de entrenamiento\n",
        "x_train = tf.image.resize(x_train, new_size)\n",
        "\n",
        "# Crear un generador de entrenamiento\n",
        "train_generator = datagen.flow(x_train, y_train, batch_size=32)\n",
        "\n",
        "# Cargar el modelo VGG19 preentrenado en ImageNet sin la capa superior\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_tensor=Input(shape=(64, 64, 3)))\n",
        "\n",
        "# Congelar las capas del modelo base\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Agregar una nueva capa de clasificación\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(512, activation='relu')(x)  # Aumentar el número de unidades a 512\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Crear el modelo final\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo usando el generador de entrenamiento\n",
        "model.fit(train_generator, validation_data=(x_test / 255.0, y_test), epochs=10)\n",
        "\n",
        "# Evaluar el modelo\n",
        "loss, accuracy = model.evaluate(x_test / 255.0, y_test)\n",
        "print(f'Pérdida: {loss:.4f}, Precisión: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "82Mf0LAEGj6D",
        "outputId": "5fd5b539-c648-403b-e327-7b4006653f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 100/1563 [>.............................] - ETA: 42:25 - loss: 1.9081 - accuracy: 0.3291"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a474c9013ca4>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Entrenar el modelo usando el generador de entrenamiento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# Evaluar el modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                         ):\n\u001b[1;32m   1741\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    855\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m       (concrete_function,\n\u001b[1;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1348\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TwYXo7xuanPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sBZ4djTzakNX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}